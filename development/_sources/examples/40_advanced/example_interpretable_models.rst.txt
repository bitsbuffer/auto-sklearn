
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_interpretable_models.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_interpretable_models.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_interpretable_models.py:


====================
Interpretable models
====================

The following example shows how to inspect the models which *auto-sklearn*
optimizes over and how to restrict them to an interpretable subset.

.. GENERATED FROM PYTHON SOURCE LINES 10-16

.. code-block:: default

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.classification









.. GENERATED FROM PYTHON SOURCE LINES 17-23

Show available classification models
====================================

We will first list all classifiers Auto-sklearn chooses from. A similar
call is available for preprocessors (see below) and regression (not shown)
as well.

.. GENERATED FROM PYTHON SOURCE LINES 23-28

.. code-block:: default


    import autosklearn.pipeline.components.classification
    for name in autosklearn.pipeline.components.classification.ClassifierChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    adaboost
    bernoulli_nb
    decision_tree
    extra_trees
    gaussian_nb
    gradient_boosting
    k_nearest_neighbors
    lda
    liblinear_svc
    libsvm_svc
    mlp
    multinomial_nb
    passive_aggressive
    qda
    random_forest
    sgd




.. GENERATED FROM PYTHON SOURCE LINES 29-31

Show available preprocessors
============================

.. GENERATED FROM PYTHON SOURCE LINES 31-36

.. code-block:: default


    import autosklearn.pipeline.components.feature_preprocessing
    for name in autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    densifier
    extra_trees_preproc_for_classification
    extra_trees_preproc_for_regression
    fast_ica
    feature_agglomeration
    kernel_pca
    kitchen_sinks
    liblinear_svc_preprocessor
    no_preprocessing
    nystroem_sampler
    pca
    polynomial
    random_trees_embedding
    select_percentile_classification
    select_percentile_regression
    select_rates_classification
    select_rates_regression
    truncatedSVD




.. GENERATED FROM PYTHON SOURCE LINES 37-39

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 39-44

.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








.. GENERATED FROM PYTHON SOURCE LINES 45-53

Build and fit a classifier
==========================

We will now only use a subset of the given classifiers and preprocessors.
Furthermore, we will restrict the ensemble size to ``1`` to only use the
single best model in the end. However, we would like to note that the
choice of which models is deemed interpretable is very much up to the user
and can change from use case to use case.

.. GENERATED FROM PYTHON SOURCE LINES 53-64

.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp',
        include_estimators=['decision_tree', 'lda', 'sgd'],
        include_preprocessors=['no_preprocessing', 'polynomial', 'select_percentile_classification'],
        ensemble_size=1,
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(ensemble_size=1,
                          include_estimators=['decision_tree', 'lda', 'sgd'],
                          include_preprocessors=['no_preprocessing', 'polynomial',
                                                 'select_percentile_classification'],
                          per_run_time_limit=30, time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp')



.. GENERATED FROM PYTHON SOURCE LINES 65-67

Print the final ensemble constructed by auto-sklearn
====================================================

.. GENERATED FROM PYTHON SOURCE LINES 67-70

.. code-block:: default


    print(automl.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:sgd:alpha': 2.7394019880335755e-07, 'classifier:sgd:average': 'False', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'log', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 0.0038175781754295085, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004, 'feature_preprocessor:polynomial:degree': 3, 'feature_preprocessor:polynomial:include_bias': 'False', 'feature_preprocessor:polynomial:interaction_only': 'True', 'classifier:sgd:eta0': 0.009982905352365661},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    ]




.. GENERATED FROM PYTHON SOURCE LINES 71-73

Get the Score of the final ensemble
===================================

.. GENERATED FROM PYTHON SOURCE LINES 73-76

.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:", sklearn.metrics.accuracy_score(y_test, predictions))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score: 0.958041958041958





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  0.859 seconds)


.. _sphx_glr_download_examples_40_advanced_example_interpretable_models.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/40_advanced/example_interpretable_models.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_interpretable_models.py <example_interpretable_models.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_interpretable_models.ipynb <example_interpretable_models.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
